{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a70e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import undetected_chromedriver as uc \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "soup = []\n",
    "keys = [\"genrative ai courses\" , \"emp monitor\" , \"almabetter\" ]\n",
    "def main(key):\n",
    "    try:\n",
    "        # Use undetected-chromedriver\n",
    "        driver = uc.Chrome(options=Options())\n",
    "        driver.get(\"https://www.google.com/\")\n",
    "        search_box = driver.find_element(By.NAME, \"q\")\n",
    "        time.sleep(2)\n",
    "        for char in key :\n",
    "            search_box.send_keys(char)\n",
    "            time.sleep(random.uniform(0.1, 0.8))\n",
    "        time.sleep(random.uniform(0.1, 0.8))\n",
    "        search_box.send_keys(Keys.ARROW_DOWN)\n",
    "        time.sleep(random.uniform(0.1, 0.8))\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "        time.sleep(5) \n",
    "\n",
    "      \n",
    "\n",
    "        # Wait for search results to load\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(EC.presence_of_element_located((By.ID, \"search\")))\n",
    "\n",
    "        # Get the page source\n",
    "        page_source = driver.page_source\n",
    "\n",
    "        # Parse the page source with BeautifulSoup\n",
    "        soup.append(BeautifulSoup(page_source, 'html.parser'))\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "    time.sleep(2)\n",
    "    driver.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    for key in keys:\n",
    "\n",
    "        main(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d121a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"keyword\": \"genrative ai courses\",\n",
      "    \"Ads\": []\n",
      "}\n",
      "{\n",
      "    \"keyword\": \"emp monitor\",\n",
      "    \"Ads\": [\n",
      "        {\n",
      "            \"Post_owner\": \"EmpMonitor\",\n",
      "            \"Link\": \"https://empmonitor.com\",\n",
      "            \"Ad_title \": \"Employee Monitoring Software - Online Employee Tracking\",\n",
      "            \"Ad_text\": \"Get real-time insights into employee performance with EmpMonitor's time tracking software. EmpMonitor: Boost productivity and security with powerful employee monitoring solutions.\",\n",
      "            \"Direct_links\": [\n",
      "                {\n",
      "                    \"Link_display_text\": \"Log In\",\n",
      "                    \"Link\": \"https://app.empmonitor.com/amember/member\",\n",
      "                    \"Description\": \"Enter the Required Details To Access Your Account.\"\n",
      "                },\n",
      "                {\n",
      "                    \"Link_display_text\": \"Contact Us\",\n",
      "                    \"Link\": \"https://empmonitor.com/contact-us/\",\n",
      "                    \"Description\": \"Fill Out the Form To Leave a Message Or Call Us For Details.\"\n",
      "                },\n",
      "                {\n",
      "                    \"Link_display_text\": \"Read The FAQs\",\n",
      "                    \"Link\": \"https://empmonitor.com/faq/\",\n",
      "                    \"Description\": \"Refer To the Common Queries On Pricing, EmpMonitor And More.\"\n",
      "                },\n",
      "                {\n",
      "                    \"Link_display_text\": \"Case Studies\",\n",
      "                    \"Link\": \"https://empmonitor.com/case-studies/\",\n",
      "                    \"Description\": \"Get Insights On How Corporates Are Using EmpMonitor And More.\"\n",
      "                }\n",
      "            ],\n",
      "            \"Small_links\": [],\n",
      "            \"Ad_position\": 1\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"keyword\": \"almabetter\",\n",
      "    \"Ads\": [\n",
      "        {\n",
      "            \"Post_owner\": \"AlmaBetter\",\n",
      "            \"Link\": \"https://almabetter.com\",\n",
      "            \"Ad_title \": \"AlmaBetter Data Science Course - Instructors from top companies\",\n",
      "            \"Ad_text\": \"India's first DS course with an IIT certification and a pay-after-placement job assurance.\",\n",
      "            \"Direct_links\": [],\n",
      "            \"Small_links\": [],\n",
      "            \"Ad_position\": 1\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "def get_details(soup , key):\n",
    "\n",
    "    data = {\n",
    "        \"keyword\" : key,\n",
    "        \"Ads\" : []\n",
    "    }\n",
    "\n",
    "    new_soup = soup\n",
    "\n",
    "\n",
    "    webs = new_soup.find_all('div', class_='uEierd')\n",
    "\n",
    "\n",
    "    for index, web in enumerate(webs):\n",
    "        \n",
    "\n",
    "        sub_urls = []\n",
    "    \n",
    "        small_urls = []\n",
    "\n",
    "        sub_webs = web.find_all('div', class_='iCzAIb') or  web.find_all('div', class_='Ktlw8e') or web.find_all('div', class_='nS9mjd E8hWLe lndKif SVMeif OcpZAb')\n",
    "\n",
    "        for sub_web in sub_webs:\n",
    "            \n",
    "            \n",
    "            t = sub_web.find_all('div', class_='DkX4ue') or sub_web.find_all('div' , class_ = \"aFn4tc DZm15c MBeuO\")\n",
    "\n",
    "\n",
    "            for  index , sub_t  in enumerate(t) :\n",
    "                try :\n",
    "\n",
    "                    sub_url = sub_web.find(\"a\" )['href']\n",
    "\n",
    "                except :\n",
    "                    sub_url = []\n",
    "\n",
    "                try:\n",
    "                    des = sub_web.find_all('div', class_='wHYlTd dFcyOb')[index].text or []\n",
    "                except:\n",
    "                    des = []\n",
    "                sub_urls.append({\n",
    "                    \"Link_display_text\":sub_t.text,\n",
    "                    \"Link\" :sub_url ,\n",
    "                    \"Description\": des\n",
    "\n",
    "                })        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        title = web.find('span', class_='pKWwCd yUTMj').text\n",
    "        url = web.find('span', class_='x2VHCd OSrXXb ob9lvb')\n",
    "        try:\n",
    "            ad_title = web.find('div', class_= 'CCgQ5 vCa9Yd QfkTvb N8QANc Va3FIb EE3Upf').text\n",
    "        except:\n",
    "            ad_title =[]\n",
    "        des = web.find('div', class_='p4wth').text\n",
    "        \n",
    "        anchor_div = web.find('div', class_='bOeY0b')\n",
    "\n",
    "        try:\n",
    "            anchors = anchor_div.find_all('a')\n",
    "        except:\n",
    "            anchors = []\n",
    "\n",
    "        for anchor in anchors:\n",
    "            small_urls.append({\n",
    "                \"Link_display_text\":anchor.text,\n",
    "                \"Link\":anchor['href']\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "        data[\"Ads\"].append( {\"Post_owner\":title ,  \"Link\":\"https://\"+url['data-dtld'] ,\"Ad_title \" : ad_title , \"Ad_text\":des , \"Direct_links\" : sub_urls, \"Small_links\" : small_urls, \"Ad_position\" : index + 1} )\n",
    "\n",
    "    return json.dumps(data, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for s , k in zip(soup , keys):\n",
    "    print(get_details(s ,  k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e372d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
